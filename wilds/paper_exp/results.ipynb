{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD                        \tTEST_ACC        TEST_ACC_STD\n",
      "camelyon                      \t0.915              nan\n",
      "camelyon_np                   \t0.836              nan\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "import os.path as osp\n",
    "from typing import Union, Dict, List\n",
    "\n",
    "#filenames=[\"camelyon\", \"camelyon_np\", \"resnet_camelyon\", \"resnet_np_camelyon\"]\n",
    "filenames=[\"camelyon\", \"camelyon_np\"]\n",
    "res_path = \"../logs/div1/\"\n",
    "\n",
    "res = defaultdict(list)\n",
    "\n",
    "print(f\"{'METHOD':<30}\\tTEST_ACC        TEST_ACC_STD\")\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    filename_complete = osp.join(res_path, f\"{filename}_results.json\")\n",
    "\n",
    "    with open(filename_complete) as f:\n",
    "        logs=json.load(f)\n",
    "        test_acc = logs[\"test\"][\"acc_avg\"]\n",
    "        test_acc_std = logs[\"test\"][\"acc_avg_std\"]\n",
    "        print(f\"{filename:<30}\\t{test_acc:.3f}              {test_acc_std:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained False  seed 2\n",
      "0.5664769654864343\n",
      "\n",
      "pretrained False  seed 3\n",
      "0.538223832698547\n",
      "\n",
      "pretrained False  seed 4\n",
      "0.5425295792777542\n",
      "\n",
      "mean  0.5490767924875786  std 0.012428713494530093\n",
      "pretrained True  seed 2\n",
      "0.5730625058776508\n",
      "\n",
      "pretrained True  seed 3\n",
      "0.5814260356420746\n",
      "\n",
      "pretrained True  seed 4\n",
      "0.5894589475478441\n",
      "\n",
      "mean  0.5813158296891898  std 0.006694272869403668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for p in [False,True]:\n",
    "    tot_sims = []\n",
    "    for i in [2,3,4]:\n",
    "        print(f\"pretrained {p}  seed {i}\")\n",
    "\n",
    "        with open(f\"/datasets/home/hbenoit/sim_seed{i}_p={p}.txt\", \"r\") as f:\n",
    "        \n",
    "            sims = np.array([float(x.replace(\"\\n\",\"\")) for x in list(f.readlines())])\n",
    "            cutoff = len(sims)//10\n",
    "            print(sims[:-cutoff].mean())\n",
    "            tot_sims.append(sims[:-cutoff].mean())\n",
    "            print()\n",
    "    \n",
    "    tot_sims = np.array(tot_sims)\n",
    "    print(f\"mean  {tot_sims.mean()}  std {tot_sims.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5617409013965299"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5804060218978102"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46620124113475175"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47069263558263813, 0.03464007089395604)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_p_sims=np.array([0.49626706484641636, 0.421720297029703, 0.4940905448717949])\n",
    "cam_p_sims.mean(), cam_p_sims.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5290244549091591, 0.04732065404001418)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_np_sims=np.array([0.5404661016949153, 0.5804060218978102, 0.46620124113475175])\n",
    "cam_np_sims.mean(), cam_np_sims.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "camelyon training_mode=div10\n",
      "h0\t\th1\t\tsimilarity\n",
      "0.866 +- 0.017 \t0.802 +- 0.056 \t0.90988 +- 0.077\n",
      "\n",
      "camelyon_np training_mode=div10\n",
      "h0\t\th1\t\tsimilarity\n",
      "0.856 +- 0.009 \t0.851 +- 0.013 \t0.98260 +- 0.004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "res_path=\"/datasets/home/hbenoit/DivDis-exp/wilds/logs\"\n",
    "filenames=[\"camelyon\", \"camelyon_np\"]\n",
    "\n",
    "seeds = [2,3,4]\n",
    "num_heads = 2\n",
    "training_modes=[\"div10\", \"ERM\"]\n",
    "\n",
    "\n",
    "def print_divdis_results(res_path, training_mode, seeds, filename):\n",
    "    sims=[]\n",
    "    test_acc= defaultdict(list)\n",
    "    for seed in  seeds:\n",
    "        res_folder = osp.join(res_path,training_mode,f\"{filename}_seed{seed}\")\n",
    "        path = osp.join(res_folder, f\"camelyon17_split:test_seed:{seed}_epoch:best_preds.json\")\n",
    "        with open(path) as f:\n",
    "            res=json.load(f)\n",
    "            preds = {}\n",
    "            epoch_y_true = torch.tensor(res[\"epoch_y_true\"])\n",
    "            for i in range(num_heads):\n",
    "                preds[f\"h_{i}\"] = torch.tensor(res[f\"epoch_y_pred_res_h_{i}\"])\n",
    "                test_acc[f\"h_{i}\"].append((preds[f\"h_{i}\"] == epoch_y_true).float().mean().item())\n",
    "            sim = (preds[\"h_0\"] == preds[\"h_1\"]).float().mean()\n",
    "            sims.append(sim)\n",
    "        \n",
    "        #save_preds_path= osp.join(res_folder, \"save_preds.json\")\n",
    "        #if osp.exists(save_preds_path):\n",
    "        #    with open(save_preds_path) as f:\n",
    "        #        save_preds = json.load(f)\n",
    "        #        test = save_preds[\"res_h0\"][\"acc_avg\"]\n",
    "        #        print(\"h0 test\")\n",
    "    sims_mean = np.array(sims).mean()\n",
    "    sims_std = np.array(sims).std()\n",
    "    print(\"\")\n",
    "    print(filename, f\"training_mode={training_mode}\")\n",
    "    print(\"h0\\t\\th1\\t\\tsimilarity\")\n",
    "    res_string = \"\"\n",
    "    for k in test_acc:\n",
    "        mean_test_acc = np.array(test_acc[k]).mean()\n",
    "        std_test_acc = np.array(test_acc[k]).std()\n",
    "        res_string = res_string + f\"{mean_test_acc:.3f} +- {std_test_acc:.3f} \\t\"\n",
    "    res_string = res_string + f\"{sims_mean:.5f} +- {sims_std:.3f}\"\n",
    "    print(res_string)\n",
    "\n",
    "\n",
    "for training_mode in training_modes:\n",
    "    print()\n",
    "    for filename in filenames:\n",
    "        if \"div\" in training_mode:\n",
    "            print_divdis_results(res_path=res_path, training_mode=training_mode, seeds=seeds, filename=filename)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/datasets/home/hbenoit/DivDis-exp/wilds/')\n",
    "from algorithms.DivDis import DivDis, MultiHeadModel\n",
    "from models.initializer import initialize_torchvision_model\n",
    "from utils import load, move_to\n",
    "import wilds\n",
    "from wilds.common.data_loaders import get_eval_loader, get_train_loader\n",
    "from transforms import initialize_transform\n",
    "import json\n",
    "from argparse import Namespace\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "\n",
    "path = \"/datasets/home/hbenoit/DivDis-exp/wilds/logs/div10/camelyon_seed2/camelyon17_seed:2_epoch:best_model.pth\"\n",
    "\n",
    "\n",
    "res = torch.load(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadModel(nn.Module):\n",
    "    def __init__(self, featurizer, classifier, heads=2):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.featurizer = featurizer\n",
    "        in_dim, out_dim = classifier.in_features, classifier.out_features * self.heads\n",
    "        self.heads_classifier = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.featurizer(x)\n",
    "        outputs = self.heads_classifier(features)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Overrides single_model_algorithm.process_batch().\n",
    "        Args:\n",
    "            - batch (x, y, m): a batch of data yielded by data loaders\n",
    "        Output:\n",
    "            - results (dictionary): information about the batch\n",
    "                - y_true (Tensor): ground truth labels for batch\n",
    "\n",
    "                - y_pred (Tensor): model output for batch\n",
    "\n",
    "        \"\"\"\n",
    "        # Labeled examples\n",
    "        x, y_true, metadata = batch\n",
    "        x = move_to(x, DEVICE)\n",
    "        y_true = move_to(y_true, DEVICE)\n",
    "        # package the results\n",
    "        results = { \"y_true\": y_true, \"metadata\": metadata}\n",
    "\n",
    "        pred = self.forward(x)\n",
    "        preds_chunked = torch.chunk(pred, self.heads, dim=-1)\n",
    "        for i in range(self.heads):\n",
    "            results[f\"y_pred_{i}\"] = preds_chunked[i]\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "featurizer = initialize_torchvision_model(\n",
    "    name=\"densenet121\", d_out=None, **{\"pretrained\":False}\n",
    ")\n",
    "classifier = nn.Linear(featurizer.d_out, 4)\n",
    "\n",
    "import copy\n",
    "\n",
    "model= res[\"algorithm\"]\n",
    "\n",
    "new_model = copy.deepcopy(model)\n",
    "for key in model:\n",
    "    if \"model.featurizer.\" in key:\n",
    "        new_key = key.replace(\"model.featurizer.\" ,\"\")\n",
    "        new_model[new_key] = model[key]\n",
    "        del new_model[key]\n",
    "    elif \"model.heads_classifier.\" in key:\n",
    "        new_key = key.replace(\"model.heads_classifier.\",\"\")\n",
    "        new_model[new_key] = model[key]\n",
    "        del new_model[key]\n",
    "\n",
    "featurizer.load_state_dict(new_model,strict=False)\n",
    "classifier.load_state_dict({\"weight\":new_model[\"weight\"], \"bias\":new_model[\"bias\"]}, strict=True)\n",
    "\n",
    "algorithm = MultiHeadModel(featurizer=featurizer, classifier=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialize_transform() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-72609b8e1779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m eval_transform = initialize_transform(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtransform_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"image_base\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize_transform() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_eval_loader\n",
    "\n",
    "dataset = get_dataset(\n",
    "            dataset=\"camelyon17\",\n",
    "            root_dir=\"/datasets/home/hbenoit/D-BAT-exp/datasets/\",\n",
    "            unlabeled=True,\n",
    "            download=False,\n",
    "        )\n",
    "\n",
    "\n",
    "eval_transform = initialize_transform(\n",
    "    transform_name=\"image_base\",\n",
    "    dataset=dataset,\n",
    "    is_training=False,\n",
    ")\n",
    "\n",
    "test_unlabeled = dataset.get_subset(split=\"test_unlabeled\")\n",
    "test_loader = get_eval_loader(loader=\"standard\", dataset=test_unlabeled, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c5ff216abdff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py38/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "for x in test_loader:\n",
    "\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_unlabeled': 10, 'val_unlabeled': 11, 'test_unlabeled': 12}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds.datasets.camelyon17_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/swav/archive/main.zip\" to /home/hbenoit/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deepcluster/swav_800ep_pretrain.pth.tar\" to /home/hbenoit/.cache/torch/hub/checkpoints/swav_800ep_pretrain.pth.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313e6342591e4ed2b0ffa1345c01f487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/108M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model = torch.hub.load('facebookresearch/swav:main', 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
